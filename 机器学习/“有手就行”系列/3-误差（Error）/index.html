<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.1.1">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-programming-flag.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-programming-flag.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"yangchen.pro","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="不同的模型，它对应的误差（Error）是不同的；越复杂的模型，也许表现会越差，所以本文要讨论的问题是：误差是如何产生的。">
<meta property="og:type" content="article">
<meta property="og:title" content="3-误差（Error）">
<meta property="og:url" content="https://yangchen.pro/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E2%80%9C%E6%9C%89%E6%89%8B%E5%B0%B1%E8%A1%8C%E2%80%9D%E7%B3%BB%E5%88%97/3-%E8%AF%AF%E5%B7%AE%EF%BC%88Error%EF%BC%89/index.html">
<meta property="og:site_name" content="CBlog">
<meta property="og:description" content="不同的模型，它对应的误差（Error）是不同的；越复杂的模型，也许表现会越差，所以本文要讨论的问题是：误差是如何产生的。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://yangchen.pro/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E2%80%9C%E6%9C%89%E6%89%8B%E5%B0%B1%E8%A1%8C%E2%80%9D%E7%B3%BB%E5%88%97/3-%E8%AF%AF%E5%B7%AE%EF%BC%88Error%EF%BC%89/estimator.png">
<meta property="og:image" content="https://yangchen.pro/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E2%80%9C%E6%9C%89%E6%89%8B%E5%B0%B1%E8%A1%8C%E2%80%9D%E7%B3%BB%E5%88%97/3-%E8%AF%AF%E5%B7%AE%EF%BC%88Error%EF%BC%89/bias-variance.png">
<meta property="og:image" content="https://yangchen.pro/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E2%80%9C%E6%9C%89%E6%89%8B%E5%B0%B1%E8%A1%8C%E2%80%9D%E7%B3%BB%E5%88%97/3-%E8%AF%AF%E5%B7%AE%EF%BC%88Error%EF%BC%89/5000-tests.png">
<meta property="og:image" content="https://yangchen.pro/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E2%80%9C%E6%9C%89%E6%89%8B%E5%B0%B1%E8%A1%8C%E2%80%9D%E7%B3%BB%E5%88%97/3-%E8%AF%AF%E5%B7%AE%EF%BC%88Error%EF%BC%89/model-bias.png">
<meta property="og:image" content="https://yangchen.pro/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E2%80%9C%E6%9C%89%E6%89%8B%E5%B0%B1%E8%A1%8C%E2%80%9D%E7%B3%BB%E5%88%97/3-%E8%AF%AF%E5%B7%AE%EF%BC%88Error%EF%BC%89/bias-vs-variance.png">
<meta property="og:image" content="https://yangchen.pro/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E2%80%9C%E6%9C%89%E6%89%8B%E5%B0%B1%E8%A1%8C%E2%80%9D%E7%B3%BB%E5%88%97/3-%E8%AF%AF%E5%B7%AE%EF%BC%88Error%EF%BC%89/large-bias.png">
<meta property="og:image" content="https://yangchen.pro/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E2%80%9C%E6%9C%89%E6%89%8B%E5%B0%B1%E8%A1%8C%E2%80%9D%E7%B3%BB%E5%88%97/3-%E8%AF%AF%E5%B7%AE%EF%BC%88Error%EF%BC%89/large-variance.png">
<meta property="og:image" content="https://yangchen.pro/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E2%80%9C%E6%9C%89%E6%89%8B%E5%B0%B1%E8%A1%8C%E2%80%9D%E7%B3%BB%E5%88%97/3-%E8%AF%AF%E5%B7%AE%EF%BC%88Error%EF%BC%89/regularization-illustration.png">
<meta property="og:image" content="https://yangchen.pro/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E2%80%9C%E6%9C%89%E6%89%8B%E5%B0%B1%E8%A1%8C%E2%80%9D%E7%B3%BB%E5%88%97/3-%E8%AF%AF%E5%B7%AE%EF%BC%88Error%EF%BC%89/model-selection.png">
<meta property="og:image" content="https://yangchen.pro/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E2%80%9C%E6%9C%89%E6%89%8B%E5%B0%B1%E8%A1%8C%E2%80%9D%E7%B3%BB%E5%88%97/3-%E8%AF%AF%E5%B7%AE%EF%BC%88Error%EF%BC%89/cross-validation.png">
<meta property="og:image" content="https://yangchen.pro/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E2%80%9C%E6%9C%89%E6%89%8B%E5%B0%B1%E8%A1%8C%E2%80%9D%E7%B3%BB%E5%88%97/3-%E8%AF%AF%E5%B7%AE%EF%BC%88Error%EF%BC%89/n-flod-cross-validation.png">
<meta property="article:published_time" content="2020-10-02T05:59:27.000Z">
<meta property="article:modified_time" content="2020-10-02T06:57:57.139Z">
<meta property="article:author" content="YANG CHEN">
<meta property="article:tag" content="机器学习">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://yangchen.pro/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E2%80%9C%E6%9C%89%E6%89%8B%E5%B0%B1%E8%A1%8C%E2%80%9D%E7%B3%BB%E5%88%97/3-%E8%AF%AF%E5%B7%AE%EF%BC%88Error%EF%BC%89/estimator.png">

<link rel="canonical" href="https://yangchen.pro/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E2%80%9C%E6%9C%89%E6%89%8B%E5%B0%B1%E8%A1%8C%E2%80%9D%E7%B3%BB%E5%88%97/3-%E8%AF%AF%E5%B7%AE%EF%BC%88Error%EF%BC%89/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>3-误差（Error） | CBlog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="alternate" href="/atom.xml" title="CBlog" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">CBlog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">记录科研日常</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签<span class="badge">3</span></a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类<span class="badge">3</span></a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档<span class="badge">8</span></a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>

  <a href="https://github.com/ycv587" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://yangchen.pro/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E2%80%9C%E6%9C%89%E6%89%8B%E5%B0%B1%E8%A1%8C%E2%80%9D%E7%B3%BB%E5%88%97/3-%E8%AF%AF%E5%B7%AE%EF%BC%88Error%EF%BC%89/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="YANG CHEN">
      <meta itemprop="description" content="is me">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="CBlog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          3-误差（Error）
        </h1>

        <div class="post-meta">

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2020-10-02 13:59:27 / 修改时间：14:57:57" itemprop="dateCreated datePublished" datetime="2020-10-02T13:59:27+08:00">2020-10-02</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E2%80%9C%E6%9C%89%E6%89%8B%E5%B0%B1%E8%A1%8C%E2%80%9D%E7%B3%BB%E5%88%97/" itemprop="url" rel="index"><span itemprop="name">“有手就行”系列</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span id="busuanzi_value_page_pv"></span>
            </span><br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>12k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>11 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>不同的模型，它对应的误差（Error）是不同的；越复杂的模型，也许表现会越差，所以本文要讨论的问题是：误差是如何产生的。</p>
<a id="more"></a>
<ul>
<li>error due to <span style="background-color:#FFF000">bias</span></li>
<li>error due to <span style="background-color:#FFF000">variance</span></li>
</ul>
<p>了解error的来源其实是很重要的，因为我们可以针对它挑选适当的方法来提升自己的模型，提高模型的准确率，而不会毫无头绪</p>
<center><img src="/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E2%80%9C%E6%9C%89%E6%89%8B%E5%B0%B1%E8%A1%8C%E2%80%9D%E7%B3%BB%E5%88%97/3-%E8%AF%AF%E5%B7%AE%EF%BC%88Error%EF%BC%89/estimator.png" style="width:60%;"></center>


<h4 id="1-抽样分布"><a href="#1-抽样分布" class="headerlink" title="1. 抽样分布"></a>1. 抽样分布</h4><h5 id="1-1-真值-widehat-y-和估测值-y"><a href="#1-1-真值-widehat-y-和估测值-y" class="headerlink" title="1.1 真值 $\widehat{y}$ 和估测值 $y^*$"></a>1.1 真值 $\widehat{y}$ 和估测值 $y^*$</h5><p>$\widehat{y}$ 表示那个真正的function，而 $f^*$ 表示这个 $\widehat{f}$ 的估测值estimator</p>
<p>就好像在打靶，$\widehat{f}$ 是靶的中心点，收集到一些data做training以后，你会得到一个你觉得最好的function即 $f^<em>$，这个$f^</em>$落在靶上的某个位置，它跟靶中心有一段距离，这段距离就是由Bias和variance决定的</p>
<p>bias：偏差；variance：方差  -&gt; 实际上对应着物理实验中系统误差和随机误差的概念，假设有n组数据，每一组数据都会产生一个相应的$f^<em>$，此时bias表示所有$f^</em>$的平均落靶位置和真值靶心的距离，variance表示这些$f^*$的集中程度</p>
<h5 id="1-2-抽样分布的理论-概率论与数理统计"><a href="#1-2-抽样分布的理论-概率论与数理统计" class="headerlink" title="1.2 抽样分布的理论(概率论与数理统计)"></a>1.2 抽样分布的理论(概率论与数理统计)</h5><p>假设独立变量为x(这里的x代表每次独立地从不同的training data里训练找到的$f^*$)，那么</p>
<p>总体期望$E(x)=u$ ；总体方差$Var(x)=\sigma^2$ </p>
<h6 id="1）-用样本均值-overline-x-估测总体期望-u"><a href="#1）-用样本均值-overline-x-估测总体期望-u" class="headerlink" title="1） 用样本均值 $\overline{x}$ 估测总体期望 $u$"></a>1） 用样本均值 $\overline{x}$ 估测总体期望 $u$</h6><p>由于我们只有有限组样本 $Sample \ N \ points:\{x^1,x^2,…,x^N\}$，故：</p>
<ul>
<li>样本均值 $\overline{x}=\frac{1}{N}\sum\limits_{i=1}^{N}x^i$ </li>
<li>样本均值的期望 $E(\overline{x})=E(\frac{1}{N}\sum\limits_{i=1}^{N}x^i)=u$ ; </li>
<li>样本均值的方差 $Var(\overline{x})=\frac{\sigma^2}{N}$</li>
</ul>
<p><strong>样本均值 $\overline{x}$的期望是总体期望$u$</strong>，也就是说 $\overline{x}$ 是按概率对称地分布在总体期望 $u$ 的两侧的；而 $\overline{x}$ 分布的密集程度取决于 N，即数据量的大小，如果 N 比较大，$\overline{x}$ 就会比较集中，如果 N 比较小，$\overline{x}$ 就会以 $u$ 为中心分散开来</p>
<p>综上，<span style="background-color:#FFF000">样本均值 $\overline{x}$ 以总体期望 $u$ 为中心对称分布，可以用来估测总体期望 $u$</span></p>
<h6 id="2）用样本方差-s-2-估测总体方差-sigma-2"><a href="#2）用样本方差-s-2-估测总体方差-sigma-2" class="headerlink" title="2）用样本方差 $s^2$ 估测总体方差 $\sigma^2$"></a>2）用样本方差 $s^2$ 估测总体方差 $\sigma^2$</h6><p>由于我们只有有限组样本 $Sample \ N \ points:\{x^1,x^2,…,x^N\}$，故</p>
<p>样本均值$\overline{x}=\frac{1}{N}\sum\limits_{i=1}^{N}x^i$ ；样本方差$s^2=\frac{1}{N-1}\sum\limits_{i=1}^N(x^i-\overline{x})^2$ ；样本方差的期望$E(s^2)=\sigma^2$ ； 样本方差的方差$Var(s^2)=\frac{2\sigma^4}{N-1}$</p>
<p><strong>样本方差$s^2$的期望是总体方差$\sigma^2$</strong>，而$s^2$分布的密集程度也取决于N</p>
<p>同理，==样本方差$s^2$以总体方差$\sigma^2$为中心对称分布，可以用来估测总体方差$\sigma^2$==</p>
<h4 id="2-回到regression的问题上来"><a href="#2-回到regression的问题上来" class="headerlink" title="2 回到regression的问题上来"></a>2 回到regression的问题上来</h4><p>现在我们要估测的是靶的中心 $\widehat{f}$，每次collect data训练出来的 $f^*$ 是打在靶上的某个点；产生的error取决于：</p>
<ul>
<li>多次实验得到的 $f^*$ 的期望 $\overline{f}$ 与靶心 $\widehat{f}$ 之间的 bias——$E(f^*)$，可以形象地理解为瞄准的位置和靶心的距离的偏差</li>
<li>多次实验的 $f^*$ 之间的 variance——$Var(f^*)$ ，可以形象地理解为多次打在靶上的点的集中程度</li>
</ul>
<center><img src="/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E2%80%9C%E6%9C%89%E6%89%8B%E5%B0%B1%E8%A1%8C%E2%80%9D%E7%B3%BB%E5%88%97/3-%E8%AF%AF%E5%B7%AE%EF%BC%88Error%EF%BC%89/bias-variance.png"></center>

<p>说到这里，可能会产生一个疑惑：我们之前不就只做了一次实验吗？我们就collect了十笔data，然后training出来了一个$f^*$，然后就结束了。那怎么找很多个$f^*$呢？怎么知道它的bias和variance有多大呢？</p>
<h5 id="2-1-f-取决于model的复杂程度以及data的数量"><a href="#2-1-f-取决于model的复杂程度以及data的数量" class="headerlink" title="2.1 $f^*$ 取决于model的复杂程度以及data的数量"></a>2.1 $f^*$ 取决于model的复杂程度以及data的数量</h5><p>假设这里有多个平行宇宙，每个空间里都在用10只宝可梦的data去找$f^*$，由于不同宇宙中宝可梦的data是不同的，因此即使使用的是同一个model，最终获得的$f^*$都会是不同的</p>
<p>于是我们做100次相同的实验，把这100次实验找出来的100条$f^*$的分布画出来</p>
<h5 id="2-2-f-的variance取决于model的复杂程度和data的数量"><a href="#2-2-f-的variance取决于model的复杂程度和data的数量" class="headerlink" title="2.2 $f^*$的variance取决于model的复杂程度和data的数量"></a>2.2 $f^*$的variance取决于model的复杂程度和data的数量</h5><p>$f^*$的variance是由model决定的，一个简单的model在不同的training data下可以获得比较稳定分布的$f^*$，而复杂的model在不同的training data下的分布比较杂乱(如果data足够多，那复杂的model也可以得到比较稳定的分布)</p>
<p>如果采用比较简单的model，那么每次在不同data下的实验所得到的不同的$f^*$之间的variance是比较小的，就好像说，你在射击的时候，每次击中的位置是差不多的，就如同下图中的linear model，100次实验找出来的$f^*$都是差不多的</p>
<p>但是如果model比较复杂，那么每次在不同data下的实验所得到的不同的$f^*$之间的variance是比较大的，它的散布就会比较开，就如同下图中含有高次项的model，每一条$f^*$都长得不太像，并且散布得很开</p>
<blockquote>
<p>那为什么比较复杂的model，它的散布就比较开呢？比较简单的model，它的散布就比较密集呢？</p>
</blockquote>
<p>原因其实很简单，其实前面在讲regularization正规化的时候也提到了部分原因。简单的model实际上就是没有高次项的model，或者高次项的系数非常小的model，这样的model表现得相当平滑，受到不同的data的影响是比较小的</p>
<p>举一个很极端的例子，我们的整个model(function set)里面，就一个function：f=c，这个function只有一个常数项，因此无论training data怎么变化，从这个最简单的model里找出来的$f^*$都是一样的，它的variance就是等于0</p>
<h5 id="2-3-f-的bias只取决于model的复杂程度"><a href="#2-3-f-的bias只取决于model的复杂程度" class="headerlink" title="2.3 $f^*$ 的bias只取决于model的复杂程度"></a>2.3 $f^*$ 的bias只取决于model的复杂程度</h5><p>bias是说，我们把所有的$f^*$平均起来得到$E(f^*)=\overline{f^*}$，这个$\overline{f^*}$与真值$\widehat{f}$有多接近</p>
<p>当然这里会有一个问题是说，总体的真值$\widehat{f}$我们根本就没有办法知道，因此这里只是假定了一个$\widehat{f}$</p>
<p>下面的图示中，<strong>红色</strong>线条部分代表5000次实验分别得到的$f^*$，<strong>黑色</strong>线条部分代表真实值$\widehat{f}$，<strong>蓝色</strong>线条部分代表5000次实验得到的$f^*$的平均值$\overline{f}$</p>
<center><img src="/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E2%80%9C%E6%9C%89%E6%89%8B%E5%B0%B1%E8%A1%8C%E2%80%9D%E7%B3%BB%E5%88%97/3-%E8%AF%AF%E5%B7%AE%EF%BC%88Error%EF%BC%89/5000-tests.png" style="width:60%;"></center>

<p>根据上图我们发现，当model比较简单的时候，每次实验得到的$f^*$之间的variance会比较小，这些$f^*$会稳定在一个范围内，但是它们的平均值$\overline{f}$距离真实值$\widehat{f}$会有比较大的偏差；而当model比较复杂的时候，每次实验得到的$f^*$之间的variance会比较大，实际体现出来就是每次重新实验得到的$f^*$都会与之前得到的有较大差距，但是这些差距较大的$f^*$的平均值$\overline{f}$却和真实值$\widehat{f}$比较接近</p>
<p>上图分别是含有一次项、三次项和五次项的model做了5000次实验后的结果，你会发现model越复杂，比如含有5次项的model那一幅图，每一次实验得到的$f^*$几乎是杂乱无章，遍布整幅图的；但是他们的平均值却和真实值$\widehat{f}$吻合的很好。也就是说，复杂的model，单次实验的结果是没有太大参考价值的，但是如果把考虑多次实验的结果的平均值，也许会对最终的结果有帮助</p>
<p>注：这里的单次实验指的是，用一组training data训练出model的一组有效参数以构成$f^*$(每次独立实验使用的training data都是不同的)</p>
<p><strong>因此：</strong></p>
<ul>
<li>如果是一个比较简单的model，那它有比较小的variance和比较大的bias。就像下图中左下角的打靶模型，每次实验的$f^*$都比较集中，但是他们平均起来距离靶心会有一段距离(比较适合实验次数少甚至只有单次实验的情况)</li>
<li>如果是一个比较复杂的model，每次实验找出来的$f^*$都不一样，它有比较大的variance但是却有比较小的bias。就像下图中右下角的打靶模型，每次实验的$f^*$都比较分散，但是他们平均起来的位置与靶心比较接近(比较适合多次实验的情况)</li>
</ul>
<center><img src="/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E2%80%9C%E6%9C%89%E6%89%8B%E5%B0%B1%E8%A1%8C%E2%80%9D%E7%B3%BB%E5%88%97/3-%E8%AF%AF%E5%B7%AE%EF%BC%88Error%EF%BC%89/model-bias.png" style="width:60%;"></center>

<h5 id="2-4-为什么会这样？"><a href="#2-4-为什么会这样？" class="headerlink" title="2.4 为什么会这样？"></a>2.4 为什么会这样？</h5><p>实际上我们的model就是一个function set，当你定好一个model的时候，实际上就已经定好这个function set的范围了，那个最好的function只能从这个function set里面挑出来</p>
<p>如果是一个简单的model，它的function set的space是比较小的，这个范围可能根本就没有包含你的target；如果这个function set没有包含target，那么不管怎么sample，平均起来永远不可能是target(这里的space指上图中左下角那个被model圈起来的空间)</p>
<p>如果这个model比较复杂，那么这个model所代表的function set的space是比较大的(简单的model实际上就是复杂model的子集)，那它就很有可能包含target，只是它没有办法找到那个target在哪，因为你给的training data不够，你给的training data每一次都不一样，所以他每一次找出来的$f^*$都不一样，但是如果他们是散布在这个target附近的，那平均起来，实际上就可以得到和target比较接近的位置(这里的space指上图中右下角那个被model圈起来的空间)</p>
<h4 id="3-Bias-vs-Variance"><a href="#3-Bias-vs-Variance" class="headerlink" title="3. Bias vs Variance"></a>3. Bias vs Variance</h4><p>由前面的讨论可知，比较简单的model，variance比较小，bias比较大；而比较复杂的model，bias比较小，variance比较大</p>
<h5 id="3-1-bias和variance对error的影响"><a href="#3-1-bias和variance对error的影响" class="headerlink" title="3.1 bias和variance对error的影响"></a>3.1 bias和variance对error的影响</h5><p>因此下图中(也就是之前我们得到的从最高项为一次项到五次项的五个model的error表现)，绿色的线代表variance造成的error，红色的线代表bias造成的error，蓝色的线代表这个model实际观测到的error</p>
<p>$error_{实际}=error_{variance}+error_{bias}——蓝线为红线和绿线之和$</p>
<p>可以发现，随着model的逐渐复杂：</p>
<ul>
<li>bias逐渐减小，bias所造成的error也逐渐下降，也就是打靶的时候瞄得越来越准，体现为图中的红线</li>
<li>variance逐渐变大，variance所造成的error也逐渐增大，也就是虽然瞄得越来越准，但是每次射出去以后，你的误差是越来越大的，体现为图中的绿线</li>
<li>当bias和variance这两项同时被考虑的时候，得到的就是图中的蓝线，也就是实际体现出来的error的变化；实际观测到的error先是减小然后又增大，因此实际error为最小值的那个点，即为bias和variance的error之和最小的点，就是表现最好的model</li>
<li></li>
<li>==<strong>如果实际error主要来自于variance很大，这个状况就是overfitting过拟合；如果实际error主要来自于bias很大，这个状况就是underfitting欠拟合</strong>==(可以理解为，overfitting就是过分地包围了靶心所在的space，而underfitting则是还未曾包围到靶心所在的space)</li>
</ul>
<center><img src="/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E2%80%9C%E6%9C%89%E6%89%8B%E5%B0%B1%E8%A1%8C%E2%80%9D%E7%B3%BB%E5%88%97/3-%E8%AF%AF%E5%B7%AE%EF%BC%88Error%EF%BC%89/bias-vs-variance.png" style="width:60%;"></center>

<p>这就是为什么我们之前要先计算出每一个model对应的error(每一个model都有唯一对应的$f^*$，因此也有唯一对应的error)，再挑选error最小的model的原因，只有这样才能综合考虑bias和variance的影响，找到一个实际error最小的model</p>
<h5 id="3-2-必须要知道自己的error主要来自于哪里"><a href="#3-2-必须要知道自己的error主要来自于哪里" class="headerlink" title="3.2 必须要知道自己的error主要来自于哪里"></a>3.2 必须要知道自己的error主要来自于哪里</h5><h6 id="1）你现在的问题是bias大，还是variance大？"><a href="#1）你现在的问题是bias大，还是variance大？" class="headerlink" title="1）你现在的问题是bias大，还是variance大？"></a>1）你现在的问题是bias大，还是variance大？</h6><p>当你自己在做research的时候，你必须要搞清楚，手头上的这个model，它目前主要的error是来源于哪里；你觉得你现在的问题是bias大，还是variance大</p>
<p>你应该先知道这件事情，你才能知道你的future work，你要improve你的model的时候，你应该要走哪一个方向</p>
<h6 id="2）那怎么知道现在是bias大还是variance大呢？"><a href="#2）那怎么知道现在是bias大还是variance大呢？" class="headerlink" title="2）那怎么知道现在是bias大还是variance大呢？"></a>2）那怎么知道现在是bias大还是variance大呢？</h6><ul>
<li><p>如果model没有办法fit training data的examples，代表bias比较大，这时是underfitting</p>
<p>  形象地说，就是该model找到的$f^*$上面并没有training data的大部分样本点，如下图中的linear model，我们只是example抽样了这几个蓝色的样本点，而这个model甚至没有fit这少数几个蓝色的样本点(这几个样本点没有在$f^*$上)，代表说这个model跟正确的model是有一段差距的，所以这个时候是bias大的情况，是underfitting</p>
</li>
<li><p>如果model可以fit training data，在training data上得到小的error，但是在testing data上，却得到一个大的error，代表variance比较大，这时是overfitting</p>
</li>
</ul>
<h6 id="3）如何针对性地处理bias大-or-variance大的情况呢？"><a href="#3）如何针对性地处理bias大-or-variance大的情况呢？" class="headerlink" title="3）如何针对性地处理bias大 or variance大的情况呢？"></a>3）如何针对性地处理bias大 or variance大的情况呢？</h6><p>遇到bias大或variance大的时候，你其实是要用不同的方式来处理它们</p>
<p>1、<strong>如果bias比较大</strong></p>
<p>bias大代表，你现在这个model里面可能根本没有包含你的target，$\widehat{f}$可能根本就不在你的function set里</p>
<p>对于error主要来自于bias的情况，是由于该model(function set)本来就不好，collect更多的data是没有用的，必须要从model本身出发</p>
<ul>
<li><p>redesign，重新设计你的model</p>
<ul>
<li><p>增加更多的features作为model的input输入变量</p>
<p>  比如pokemon的例子里，只考虑进化前cp值可能不够，还要考虑hp值、species种类…作为model新的input变量</p>
</li>
<li><p>让model变得更复杂，增加高次项</p>
<p>  比如原本只是linear model，现在考虑增加二次项、三次项…</p>
</li>
</ul>
</li>
</ul>
<center><img src="/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E2%80%9C%E6%9C%89%E6%89%8B%E5%B0%B1%E8%A1%8C%E2%80%9D%E7%B3%BB%E5%88%97/3-%E8%AF%AF%E5%B7%AE%EF%BC%88Error%EF%BC%89/large-bias.png" style="width:60%;"></center>

<p>2、<strong>如果variance比较大</strong></p>
<ul>
<li>增加data<ul>
<li>如果是5次式，找100个$f^*$，每次实验我们只用10只宝可梦的数据训练model，那我们找出来的100个$f^*$的散布就会像下图一样杂乱无章；但如果每次实验我们用100只宝可梦的数据训练model，那我们找出来的100个$f^*$的分布就会像下图所示一样，非常地集中</li>
<li>增加data是一个很有效控制variance的方法，假设你variance太大的话，collect data几乎是一个万能丹一样的东西，并且它不会伤害你的bias</li>
<li>但是它存在一个很大的问题是，实际上并没有办法去collect更多的data</li>
<li>如果没有办法collect更多的data，其实有一招，根据你对这个问题的理解，自己去generate更多“假的”data<ul>
<li>比如手写数字识别，因为每个人手写数字的角度都不一样，那就把所有training data里面的数字都左转15°，右转15°</li>
<li>比如做火车的影像辨识，只有从左边开过来的火车影像资料，没有从右边开过来的火车影像资料，该怎么办？实际上可以把每张图片都左右颠倒，就generate出右边的火车数据了，这样就多了一倍data出来</li>
<li>比如做语音辨识的时候，只有男生说的“你好”，没有女生说的“你好”，那就用男生的声音用一个变声器把它转化一下，这样男女生的声音就可以互相转化，这样data就可以多出来</li>
<li>比如现在你只有录音室里录下的声音，但是detection实际要在真实场景下使用的，那你就去真实场景下录一些噪音加到原本的声音里，就可以generate出符合条件的data了</li>
</ul>
</li>
</ul>
</li>
</ul>
<ul>
<li>Regularization(正规化)<ul>
<li>就是在loss function里面再加一个与model高次项系数相关的term，它会希望你的model里高次项的参数越小越好，也就是说希望你今天找出来的曲线越平滑越好；这个新加的term前面可以有一个weight，代表你希望你的曲线有多平滑</li>
<li>下图中Regularization部分，左边第一幅图是没有加regularization的test；第二幅图是加了regularization后的情况，一些怪怪的、很不平滑的曲线就不会再出现，所有曲线都集中在比较平滑的区域；第三幅图是增加weight的情况，让曲线变得更平滑</li>
<li>加了regularization以后，因为你强迫所有的曲线都要比较平滑，所以这个时候也会让你的variance变小；但regularization是可能会伤害bias的，因为它实际上调整了function set的space范围，变成它只包含那些比较平滑的曲线，这个缩小的space可能没有包含原先在更大space内的$\widehat{f}$，因此伤害了bias，所以当你做regularization的时候，需要调整regularization的weight，在variance和bias之间取得平衡</li>
</ul>
</li>
</ul>
<center><img src="/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E2%80%9C%E6%9C%89%E6%89%8B%E5%B0%B1%E8%A1%8C%E2%80%9D%E7%B3%BB%E5%88%97/3-%E8%AF%AF%E5%B7%AE%EF%BC%88Error%EF%BC%89/large-variance.png" style="width:60%;"></center>

<p>注：variance比较大的case，加以图例解释如下：(假设这里我们无法获得更多的data)</p>
<p>1、蓝色区域代表最初的情况，此时model比较复杂，function set的space范围比较大，包含了target靶心，但由于data不够，$f^*$比较分散，variance比较大</p>
<p>2、红色区域代表进行regularization之后的情况，此时model的function set范围被缩小成只包含平滑的曲线，space减小，variance当然也跟着变小，但这个缩小后的space实际上并没有包含原先已经包含的target靶心，因此该model的bias变大</p>
<p>3、橙色区域代表增大regularization的weight的情况，增大weight实际上就是放大function set的space，慢慢调整至包含target靶心，此时该model的bias变小，而相较于一开始的case，由于限定了曲线的平滑度(由weight控制平滑度的阈值)，该model的variance也比较小</p>
<p>实际上，通过regularization优化model的过程就是上述的1、2、3步骤，不断地调整regularization的weight，使model的bias和variance达到一个最佳平衡的状态(可以通过error来评价状态的好坏，weight需要慢慢调参)</p>
<center><img src="/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E2%80%9C%E6%9C%89%E6%89%8B%E5%B0%B1%E8%A1%8C%E2%80%9D%E7%B3%BB%E5%88%97/3-%E8%AF%AF%E5%B7%AE%EF%BC%88Error%EF%BC%89/regularization-illustration.png" style="width:60%;"></center>

<h4 id="4-Model-Selection"><a href="#4-Model-Selection" class="headerlink" title="4. Model Selection"></a>4. Model Selection</h4><p>我们现在会遇到的问题往往是这样：我们有很多个model可以选择，还有很多参数可以调，比如regularization的weight，那通常我们是在bias和variance之间做一些trade-off权衡</p>
<p>我们希望找一个model，它variance够小，bias也够小，这两个合起来给我们最小的testing data的error</p>
<h5 id="但是以下这些事情，是你不应该做的："><a href="#但是以下这些事情，是你不应该做的：" class="headerlink" title="但是以下这些事情，是你不应该做的："></a>但是以下这些事情，是你不应该做的：</h5><p>你手上有training set，有testing set，接下来你想知道model1、model2、model3里面，应该选哪一个model，然后你就分别用这三个model去训练出$f_1^*,f_2^*,f_3^*$，然后把它apply到testing set上面，分别得到三个error为0.9，0.7，0.5，这里很直觉地会认为是model3最好</p>
<p>但是现在可能的问题是，这个testing set是你自己手上的testing set，是你自己拿来衡量model好坏的testing set，真正的testing set是你没有的；注意到你自己手上的这笔testing set，它有自己的一个bias(这里的bias跟之前提到的略有不同，可以理解为自己的testing data跟实际的testing data会有一定的偏差存在)</p>
<p>所以你今天那这个testing set来选择最好的model的时候，它在真正的testing set上不见得是最好的model，通常是比较差的，所以你实际得到的error是会大于你在自己的testing set上估测到的0.5</p>
<p>以PM2.5预测为例，提供的数据分为training set，public testing set和private testing set三部分，其中public的testing set是供你测试自己的model的，private的testing data是你暂且未知的真正测试数据，现在你的model3在public testing set上的error为0.5，已经成功beat baseline，但是在private的testing set上，你的model3也许根本就没有beat the baseline，反而是model1和model2可能会表现地更好</p>
<center><img src="/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E2%80%9C%E6%9C%89%E6%89%8B%E5%B0%B1%E8%A1%8C%E2%80%9D%E7%B3%BB%E5%88%97/3-%E8%AF%AF%E5%B7%AE%EF%BC%88Error%EF%BC%89/model-selection.png" style="width:60%;"></center>

<h5 id="怎样做才是可靠的呢？"><a href="#怎样做才是可靠的呢？" class="headerlink" title="怎样做才是可靠的呢？"></a>怎样做才是可靠的呢？</h5><h6 id="training-data分成training-set和validation-set"><a href="#training-data分成training-set和validation-set" class="headerlink" title="training data分成training set和validation set"></a>training data分成training set和validation set</h6><p>你要做的事情是，把你的training set分成两组：</p>
<ul>
<li>一组是真正拿来training model的，叫做training set(训练集)</li>
<li>另外一组不拿它来training model，而是拿它来选model，叫做validation set(验证集)</li>
</ul>
<p>==先在training set上找出每个model最好的function $f^*$，然后用validation set来选择你的model==</p>
<p>也就是说，你手头上有3个model，你先把这3个model用training set训练出三个$f^*$，接下来看一下它们在validation set上的performance</p>
<p>假设现在model3的performance最好，那你可以直接把这个model3的结果拿来apply在testing data上</p>
<p>如果你担心现在把training set分成training和validation两部分，感觉training data变少的话，可以这样做：已经从validation决定model3是最好的model，那就定住model3不变(function的表达式不变)，然后用全部的data在model3上面再训练一次(使用全部的data去更新model3表达式的参数)</p>
<p>这个时候，如果你把这个训练好的model的$f^*$apply到public testing set上面，你可能会得到一个大于0.5的error，虽然这么做，你得到的error表面上看起来是比较大的，但是<strong>这个时候你在public set上的error才能够真正反映你在private set上的error</strong></p>
<center><img src="/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E2%80%9C%E6%9C%89%E6%89%8B%E5%B0%B1%E8%A1%8C%E2%80%9D%E7%B3%BB%E5%88%97/3-%E8%AF%AF%E5%B7%AE%EF%BC%88Error%EF%BC%89/cross-validation.png" style="width:60%;"></center>

<h6 id="考虑真实的测试集"><a href="#考虑真实的测试集" class="headerlink" title="考虑真实的测试集"></a>考虑真实的测试集</h6><p>实际上是这样一个关系：</p>
<blockquote>
<p>training data(训练集) -&gt; 自己的testing data(测试集) -&gt; 实际的testing data<br>(该流程没有考虑自己的testing data的bias)</p>
<p>training set(部分训练集) -&gt; validation set(部分验证集) -&gt; 自己的testing data(测试集) -&gt; 实际的testing data<br>(该流程使用自己的testing data和validation来模拟testing data的bias误差，可以真实地反映出在实际的data上出现的error)</p>
</blockquote>
<h6 id="真正的error"><a href="#真正的error" class="headerlink" title="真正的error"></a>真正的error</h6><p>当你得到public set上的error的时候(尽管它可能会很大)，不建议回过头去重新调整model的参数，因为当你再回去重新调整什么东西的时候，你就又会把public testing set的bias给考虑进去了，这就又回到了第一种关系，即围绕着有偏差的testing data做model的优化</p>
<p>这样的话此时你在public set上看到的performance就没有办法反映实际在private set上的performance了，因为你的model是针对public set做过优化的，虽然public set上的error数据看起来可能会更好看，但是针对实际未知的private set，这个“优化”带来的可能是反作用，反而会使实际的error变大</p>
<p>当然，你也许几乎没有办法忍住不去做这件事情，在发paper的时候，有时候你会propose一个方法，那你要attach在benchmark的corpus，如果你在testing set上得到一个差的结果，你也几乎没有办法把持自己不回头去调一下你的model，你肯定不会只是写一个paper说这个方法不work这样子(滑稽</p>
<p>因此这里只是说，你要keep in mind，如果在那个benchmark corpus上面所看到的testing的performance，它的error，肯定是大于它在real的application上应该有的值</p>
<p>比如说你现在常常会听到说，在image lab的那个corpus上面，error rate都降到3%，那个是超越人类了，但是真的是这样子吗？已经有这么多人玩过这个corpus，已经有这么多人告诉你说前面这些方法都不work，他们都帮你挑过model了，你已经用“testing” data调过参数了，所以如果你把那些model真的apply到现实生活中，它的error rate肯定是大于3%的</p>
<h6 id="如何划分training-set和validation-set？"><a href="#如何划分training-set和validation-set？" class="headerlink" title="如何划分training set和validation set？"></a>如何划分training set和validation set？</h6><p>那如果training set和validation set分坏了怎么办？如果validation也有怪怪的bias，岂不是对结果很不利？那你要做下面这件事情：</p>
<p>==<strong>N-flod Cross Validation</strong>==</p>
<p>如果你不相信某一次分train和validation的结果的话，那你就分很多种不同的样子</p>
<p>比如说，如果你做3-flod的validation，意思就是你把training set分成三份，你每一次拿其中一份当做validation set，另外两份当training；分别在每个情境下都计算一下3个model的error，然后计算一下它的average error；然后你会发现在这三个情境下的average error，是model1最好</p>
<p>然后接下来，你就把用整个完整的training data重新训练一遍model1的参数；然后再去testing data上test</p>
<p>原则上是，如果你少去根据public testing set上的error调整model的话，那你在private testing set上面得到的error往往是比较接近public testing set上的error的</p>
<p><center><img src="/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E2%80%9C%E6%9C%89%E6%89%8B%E5%B0%B1%E8%A1%8C%E2%80%9D%E7%B3%BB%E5%88%97/3-%E8%AF%AF%E5%B7%AE%EF%BC%88Error%EF%BC%89/n-flod-cross-validation.png" style="width:60%;"></center></p>
<h4 id="5-总结conclusion"><a href="#5-总结conclusion" class="headerlink" title="5. 总结conclusion"></a>5. 总结conclusion</h4><p>1、一般来说，error是bias和variance共同作用的结果</p>
<p>2、model比较简单和比较复杂的情况：</p>
<ul>
<li>当model比较简单的时候，variance比较小，bias比较大，此时$f^*$会比较集中，但是function set可能并没有包含真实值$\widehat{f}$；此时model受bias影响较大</li>
<li>当model比较复杂的时候，bias比较小，variance比较大，此时function set会包含真实值$\widehat{f}$，但是$f^*$会比较分散；此时model受variance影响较大</li>
</ul>
<p>3、区分bias大 or variance大的情况</p>
<ul>
<li><p>如果连采样的样本点都没有大部分在model训练出来的$f^*$上，说明这个model太简单，bias比较大，是欠拟合</p>
</li>
<li><p>如果样本点基本都在model训练出来的$f^*$上，但是testing data上测试得到的error很大，说明这个model太复杂，variance比较大，是过拟合</p>
</li>
</ul>
<p>4、bias大 or variance大的情况下该如何处理</p>
<ul>
<li><p>当bias比较大时，需要做的是重新设计model，包括考虑添加新的input变量，考虑给model添加高次项；然后对每一个model对应的$f^*$计算出error，选择error值最小的model(随model变复杂，bias会减小，variance会增加，因此这里分别计算error，取两者平衡点)</p>
</li>
<li><p>当variance比较大时，一个很好的办法是增加data(可以凭借经验自己generate data)，当data数量足够时，得到的$f^*$实际上是比较集中的；如果现实中没有办法collect更多的data，那么就采用regularization正规化的方法，以曲线的平滑度为条件控制function set的范围，用weight控制平滑度阈值，使得最终的model既包含$\widehat{f}$，variance又不会太大</p>
</li>
</ul>
<p>5、如何选择model</p>
<ul>
<li>选择model的时候呢，我们手头上的testing data与真实的testing data之间是存在偏差的，因此我们要将training data分成training set和validation set两部分，经过validation挑选出来的model再用全部的training data训练一遍参数，最后用testing data去测试error，这样得到的error是模拟过testing bias的error，与实际情况下的error会比较符合</li>
</ul>

    </div>

    
    
    

    <div>
      
        <div>
    
        <div style="text-align:center;color: #ccc;font-size:14px;">-------------本文结束<i class="fa fa-paw"></i>感谢您的阅读-------------</div>
    
</div>
      
    </div>
        <div class="reward-container">
  <div>您的支持是对我最大的鼓励！</div>
  <button onclick="var qr = document.getElementById('qr'); qr.style.display = (qr.style.display === 'none') ? 'block' : 'none';">
    打赏
  </button>
  <div id="qr" style="display: none;">
      
      <div style="display: inline-block;">
        <img src="/images/wechatpay.jpg" alt="YANG CHEN 微信支付">
        <p>微信支付</p>
      </div>
      
      <div style="display: inline-block;">
        <img src="/images/alipay.jpg" alt="YANG CHEN 支付宝">
        <p>支付宝</p>
      </div>

  </div>
</div>

        

<div>
<ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>本文作者： </strong>YANG CHEN
  </li>
  <li class="post-copyright-link">
    <strong>本文链接：</strong>
    <a href="https://yangchen.pro/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E2%80%9C%E6%9C%89%E6%89%8B%E5%B0%B1%E8%A1%8C%E2%80%9D%E7%B3%BB%E5%88%97/3-%E8%AF%AF%E5%B7%AE%EF%BC%88Error%EF%BC%89/" title="3-误差（Error）">https://yangchen.pro/机器学习/“有手就行”系列/3-误差（Error）/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！
  </li>
</ul>
</div>


      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag"># 机器学习</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/%E7%BD%91%E7%BB%9C%E6%B5%8B%E9%87%8F%E4%B8%8E%E8%A1%8C%E4%B8%BA%E5%88%86%E6%9E%90/%E5%8A%A0%E5%AF%86%E6%B5%81%E9%87%8F%E8%AF%86%E5%88%AB%E8%AF%84%E4%BB%B7%E5%B8%B8%E7%94%A8%E6%8C%87%E6%A0%87/" rel="prev" title="加密流量识别评价常用指标">
      <i class="fa fa-chevron-left"></i> 加密流量识别评价常用指标
    </a></div>
      <div class="post-nav-item">
    <a href="/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E2%80%9C%E6%9C%89%E6%89%8B%E5%B0%B1%E8%A1%8C%E2%80%9D%E7%B3%BB%E5%88%97/4-%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%EF%BC%88Gradient-Descent%EF%BC%89/" rel="next" title="4-梯度下降（Gradient Descent）">
      4-梯度下降（Gradient Descent） <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-%E6%8A%BD%E6%A0%B7%E5%88%86%E5%B8%83"><span class="nav-text">1. 抽样分布</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1-1-%E7%9C%9F%E5%80%BC-widehat-y-%E5%92%8C%E4%BC%B0%E6%B5%8B%E5%80%BC-y"><span class="nav-text">1.1 真值 $\widehat{y}$ 和估测值 $y^*$</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#1-2-%E6%8A%BD%E6%A0%B7%E5%88%86%E5%B8%83%E7%9A%84%E7%90%86%E8%AE%BA-%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1"><span class="nav-text">1.2 抽样分布的理论(概率论与数理统计)</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#1%EF%BC%89-%E7%94%A8%E6%A0%B7%E6%9C%AC%E5%9D%87%E5%80%BC-overline-x-%E4%BC%B0%E6%B5%8B%E6%80%BB%E4%BD%93%E6%9C%9F%E6%9C%9B-u"><span class="nav-text">1） 用样本均值 $\overline{x}$ 估测总体期望 $u$</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#2%EF%BC%89%E7%94%A8%E6%A0%B7%E6%9C%AC%E6%96%B9%E5%B7%AE-s-2-%E4%BC%B0%E6%B5%8B%E6%80%BB%E4%BD%93%E6%96%B9%E5%B7%AE-sigma-2"><span class="nav-text">2）用样本方差 $s^2$ 估测总体方差 $\sigma^2$</span></a></li></ol></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-%E5%9B%9E%E5%88%B0regression%E7%9A%84%E9%97%AE%E9%A2%98%E4%B8%8A%E6%9D%A5"><span class="nav-text">2 回到regression的问题上来</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#2-1-f-%E5%8F%96%E5%86%B3%E4%BA%8Emodel%E7%9A%84%E5%A4%8D%E6%9D%82%E7%A8%8B%E5%BA%A6%E4%BB%A5%E5%8F%8Adata%E7%9A%84%E6%95%B0%E9%87%8F"><span class="nav-text">2.1 $f^*$ 取决于model的复杂程度以及data的数量</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2-2-f-%E7%9A%84variance%E5%8F%96%E5%86%B3%E4%BA%8Emodel%E7%9A%84%E5%A4%8D%E6%9D%82%E7%A8%8B%E5%BA%A6%E5%92%8Cdata%E7%9A%84%E6%95%B0%E9%87%8F"><span class="nav-text">2.2 $f^*$的variance取决于model的复杂程度和data的数量</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2-3-f-%E7%9A%84bias%E5%8F%AA%E5%8F%96%E5%86%B3%E4%BA%8Emodel%E7%9A%84%E5%A4%8D%E6%9D%82%E7%A8%8B%E5%BA%A6"><span class="nav-text">2.3 $f^*$ 的bias只取决于model的复杂程度</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2-4-%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BC%9A%E8%BF%99%E6%A0%B7%EF%BC%9F"><span class="nav-text">2.4 为什么会这样？</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-Bias-vs-Variance"><span class="nav-text">3. Bias vs Variance</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#3-1-bias%E5%92%8Cvariance%E5%AF%B9error%E7%9A%84%E5%BD%B1%E5%93%8D"><span class="nav-text">3.1 bias和variance对error的影响</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#3-2-%E5%BF%85%E9%A1%BB%E8%A6%81%E7%9F%A5%E9%81%93%E8%87%AA%E5%B7%B1%E7%9A%84error%E4%B8%BB%E8%A6%81%E6%9D%A5%E8%87%AA%E4%BA%8E%E5%93%AA%E9%87%8C"><span class="nav-text">3.2 必须要知道自己的error主要来自于哪里</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#1%EF%BC%89%E4%BD%A0%E7%8E%B0%E5%9C%A8%E7%9A%84%E9%97%AE%E9%A2%98%E6%98%AFbias%E5%A4%A7%EF%BC%8C%E8%BF%98%E6%98%AFvariance%E5%A4%A7%EF%BC%9F"><span class="nav-text">1）你现在的问题是bias大，还是variance大？</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#2%EF%BC%89%E9%82%A3%E6%80%8E%E4%B9%88%E7%9F%A5%E9%81%93%E7%8E%B0%E5%9C%A8%E6%98%AFbias%E5%A4%A7%E8%BF%98%E6%98%AFvariance%E5%A4%A7%E5%91%A2%EF%BC%9F"><span class="nav-text">2）那怎么知道现在是bias大还是variance大呢？</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#3%EF%BC%89%E5%A6%82%E4%BD%95%E9%92%88%E5%AF%B9%E6%80%A7%E5%9C%B0%E5%A4%84%E7%90%86bias%E5%A4%A7-or-variance%E5%A4%A7%E7%9A%84%E6%83%85%E5%86%B5%E5%91%A2%EF%BC%9F"><span class="nav-text">3）如何针对性地处理bias大 or variance大的情况呢？</span></a></li></ol></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-Model-Selection"><span class="nav-text">4. Model Selection</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E4%BD%86%E6%98%AF%E4%BB%A5%E4%B8%8B%E8%BF%99%E4%BA%9B%E4%BA%8B%E6%83%85%EF%BC%8C%E6%98%AF%E4%BD%A0%E4%B8%8D%E5%BA%94%E8%AF%A5%E5%81%9A%E7%9A%84%EF%BC%9A"><span class="nav-text">但是以下这些事情，是你不应该做的：</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%80%8E%E6%A0%B7%E5%81%9A%E6%89%8D%E6%98%AF%E5%8F%AF%E9%9D%A0%E7%9A%84%E5%91%A2%EF%BC%9F"><span class="nav-text">怎样做才是可靠的呢？</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#training-data%E5%88%86%E6%88%90training-set%E5%92%8Cvalidation-set"><span class="nav-text">training data分成training set和validation set</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#%E8%80%83%E8%99%91%E7%9C%9F%E5%AE%9E%E7%9A%84%E6%B5%8B%E8%AF%95%E9%9B%86"><span class="nav-text">考虑真实的测试集</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#%E7%9C%9F%E6%AD%A3%E7%9A%84error"><span class="nav-text">真正的error</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#%E5%A6%82%E4%BD%95%E5%88%92%E5%88%86training-set%E5%92%8Cvalidation-set%EF%BC%9F"><span class="nav-text">如何划分training set和validation set？</span></a></li></ol></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#5-%E6%80%BB%E7%BB%93conclusion"><span class="nav-text">5. 总结conclusion</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="YANG CHEN"
      src="/images/avatar.jpg">
  <p class="site-author-name" itemprop="name">YANG CHEN</p>
  <div class="site-description" itemprop="description">is me</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">8</span>
          <span class="site-state-item-name">文章</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">3</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">3</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/ycv587" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;ycv587" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:not1st@163.com" title="E-Mail → mailto:not1st@163.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>
  <div class="cc-license motion-element" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" class="cc-opacity" rel="noopener" target="_blank"><img src="/images/cc-by-nc-sa.svg" alt="Creative Commons"></a>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        


  <script src='https://unpkg.com/mermaid@7.1.2/dist/mermaid.min.js''></script>
  <script>
    if (window.mermaid) {
      mermaid.initialize({theme: 'forest'});
    }
  </script>


<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">YANG CHEN</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-area"></i>
    </span>
    <span title="站点总字数">60k字</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="站点阅读时长">54 分钟</span>
</div>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>











<script>
if (document.querySelectorAll('pre.mermaid').length) {
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/mermaid@8/dist/mermaid.min.js', () => {
    mermaid.initialize({
      theme    : '',
      logLevel : 3,
      flowchart: { curve     : 'linear' },
      gantt    : { axisFormat: '%m/%d/%Y' },
      sequence : { actorMargin: 50 }
    });
  }, window.mermaid);
}
</script>


  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    /*
    window.MathJax = {
      loader: {
          load: ['[tex]/mhchem'],
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
          packages: {'[+]': ['mhchem']},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    */
    window.MathJax = {
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        processEscapes: true
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = 'https://cdn.jsdelivr.net/npm/mathjax@2.7.8/unpacked/MathJax.js?config=TeX-MML-AM_CHTML';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

</body>
</html>
